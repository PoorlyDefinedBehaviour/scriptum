## Immutability in Languages w/o Purely Functional Data Types

Immutability in a language without purely functional data types entails more tedious and more verbose code. However, the advantages of avoiding this class of side effects outweigh the drawbacks by far. Locating a nasty bug caused by a subtle side effect in a large code base is one of the most frustrating experiences of any programmer.

### Why mutability is harmful

#### Introduction of time

Just like I/O operations mutations are a side effect that introduce time and thus adds complexity to your program. If time matters, it affects the evaluation order:

```javascript
const push = x => xs =>
  (xs.push(x), xs); //  mutation
  
const append = x => xs =>
  xs.concat([x]); // pure

const xs = [1, 2, 3],
  xs_ = [1, 2, 3];
  ys = [1, 2, 3],
  ys_ = [1, 2, 3];

push(4) (xs); // push before
console.log(xs); // logs [1, 2, 3, 4] A

console.log(xs_); // logs [1, 2, 3] A
push(4) (xs_); // push after

append(4) (ys); // append before
console.log(ys); // logs [1, 2, 3] B

console.log(ys_); // logs [1, 2, 3] B
append(4) (ys_); // append after
```
As you can see lines `A` diverge whereas lines `C` converge.

Besides mutations are implicit, that is to say you cannot tell if a function exhibits side effects or not just by looking at its name or the way it is invoked. This makes it more difficult to understand the intention of code without looking into the underlying implementations of the involved functions.

// Mutations hamper idempotency

Time has another implication: In the presence of it you need to take into account how often a function is called or if it is called at all:

```javascript
const push = x => xs => (xs.push(x), xs);
const pop = xs => [xs.pop(), xs];
const head = ([x]) => x;

const xs = [],
  ys = [1, 2];

// push(1) (xs); A
console.log(head(xs));

pop(xs); // [1] 
pop(xs); // [] B
pop(xs); // [] C
console.log(head(xs));
```
As you can see you have to be carefull if you call the function at all (`A`) or more than once (`B`). Consequently, mutations hamper with idempotency. However, there are also operations with side effects that are idempotent (`C`).

// Non-strict evaluation makes it worse

Functional programming embraces lazy evaluation as we have already seen in a previous chapter. Non-strict evaluation is a property of this lazyness and renders mutations even more harmful, because it evaluates the arguments only when needed:

```javascript
const nonStrict = thunk => ({valueOf: thunk});
const strict = x => x.valueOf();
const tag = tag => x => (console.log(tag), x);

const safeDiv = x => y =>
  strict(y) === 0
    ? 0 : x / y;

let x = nonStrict(() => tag("x") (1)),
  y = nonStrict(() => tag("y") (2)),
  z = nonStrict(() => tag("z") (0));

// non-strict evaluation

safeDiv(x) (y); // logs "y", "x" and "y"
safeDiv(x) (z); // logs "z"

// strict evaluation

safeDiv(strict(x)) (strict(y)); // logs "x" and "y"
safeDiv(strict(x)) (strict(z)); // logs "x" and "z"
```
[run code](https://repl.it/@scriptum/VerifiableCaringAdware)

Can you see that it is much harder to comprehend the non-strict logging compared to the strict one? Lazyness does not play well together with mutations. Please note that I used I/O instead of mutations in the example above, which in this context is not of importance.

Let us generalize what effect this insight has on our functional programming experience. Mutations hamper..

* parallelization
* local and equational reasoning

In other words you can rely on side effects but then it is not functional programming anymore.

### The big trade-off with imperative data structures

So if we should not rely on mutations anymore how are we supposed to handle Javascript's native data structures, which are mutable by design? You may treat them immutable, but it comes at the expense of their efficiency:

```javascript
const take = n => ([x, ...xs]) =>
//                     ^^^^^
  n === 0
    ? []
    : [x].concat(take(n - 1) (xs));
//        ^^^^^^

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // incredible inefficient
```
Both underlined lines of code are responsible for creating brand new copies of the array for each iteration, while previous copies are just garbage collected. This is ridiculously inefficient, especially if you have to deal with larger amounts of data. I would recommend using these composite types only for small data and resort to more suitable techniques otherwise. The following sections will show the most relevant approaches.

### Keeping side effects local

If you insist on relying on mutations in the context of imperative data structures, you can at least contain the risk by keeping side effects local:

```javascript
const push = x => xs =>
  (xs.push(x), xs);

const take = n => xs =>
  n === 0
    ? []
    : push(xs[n - 1]) (take(n - 1) (xs));

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // quite efficient
```
The side effect only leaks into `take`'s scope but not into the global one. Local mutations are less harmful, because the space they could cause harm in is rather limited. However, bugs caused by local mutations are still often hard to spot, because they can be quite subtle and counterintuitive. It is a fine line. As a rule of thumb I would recommend not to rely upon local mutations except for really trivial cases.

### Utilizing eta abstraction

Another technique to prevent side effects from leaking into the global scope are eta abstractions, that is, adding redundant function layers:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => xs => fold(acc => x =>
//               ^^^^^
  arrCons_(acc) (f(x)))
    ([])
      (xs);
//    ^^^^

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9]
```
[run code](https://repl.it/@scriptum/RaggedAccomplishedQueries)

In the example above the redundant lambda abstraction forces `map` to create a fresh array for each invocation.

### Associate data indirectly

If you want to associate data components that are not available upfront but are received in individual batches in the course of the program, you have three options in a language without immutable data structures:

* destructively update a mutable composite data structure
* safely update a mutable composite data structure by copying it first
* establish an indirect association by sharing structure

I want to demonstrate the last approach using a rather contrived example. The underlying idea is that each involved data component uses the same structure so that groups of data can be recovered just by considering this structure:

```javascript
const foo = {
  keyA: {
    keyB: [1, 2, 3],
    /*...*/
  },
  /*...*/
};

const bar = {
  keyA: {
    keyB: ["a", "b", "c"],
    /*...*/
  },
  /*...*/
};

const baz = {
  keyA: {
    keyB: [true, false, false],
    /*...*/
  },
  /*...*/
};
```
If we look at these three data structures it is possible to deduce from the original relations between their data components: `[1, "a", true]`, `[2, "b", false]` and `[3, "c", false]`. The downside of this approach is that it encodes data relations rather implicitly and leaves a lot of room for interpretation.

### Persistent data structures and structural sharing

At a certain point we cannot get around introducing real immutable data types. Such types have not only a persistent structure but share as much of it as possible across instances. They are referred to as persistent data structures with structural sharing. Instead of relying on subtle and counterintuitive side effects we can now program against stringent APIs which exhibit predictable and reliable behavior. These custom types are not as seamlessly incorporated into the language as native ones, of course and their handling is more verbose and more tedious. Having them in our toolbox is still a huge leap forward.

#### Inherently persistent lists

The functional single linked `List` type is inherently persistent. We can trivially mimic it in Javascript with a two element array used as a pair tuple:

```javascript
// union constructor

const union = type => (tag, o) =>
  (o[type] = type, o.tag = tag.name || tag, o);
  
const match = (tx, o) =>
  o[tx.tag] (tx);

// LIST

const List = union("List");

const Nil = List("Nil", {});

const Cons = head => tail => List(Cons, {head, tail});

const cons_ = tail => head =>
  List(Cons, {head, tail});

// Monoid

const listAppend = xs => ys =>
  listFoldr(x => acc =>
    Cons(x) (acc)) (ys) (xs);

// Foldable

const listFoldr = f => acc =>
  rec(xs =>
    match(xs, {
      Nil: _ => Base(acc),
      Cons: ({head, tail}) => Call(f(head), Step(tail))
    }));

// trampoline

const rec = f => (...args) => {
  let step = f(...args);
  const stack = [];

  while (step.tag !== "Base") {
    stack.push(step.f);
    step = f(...step.step.args);
  }

  let r = step.x;

  for (let i = stack.length - 1; i >= 0; i--) {
    r = stack[i] (r);
    
    if (r && r.tag === "Base") {
      r = r.x;
      break;
    }
  }

  return r;
};

const Base = x =>
  ({tag: "Base", x});

const Call = (f, step) =>
  ({tag: "Call", f, step});

const Step = (...args) =>
  ({tag: "Step", args});

// MAIN

const xs = Cons(1) (Cons(2) (Cons(3) (Nil))),
  ys = Cons(4) (Cons(5) (Cons(6) (Nil)));

listAppend(xs) (ys); // Cons(1) (Cons(2) (Cons(3) (Cons(4) (Cons(5) (Cons(6) (Nil))))))
```
[run code](https://repl.it/@scriptum/PeriodicMoccasinUpgrade)

The algorithm above right associatively folds `xs` and as soon as it reaches `Nil` it appends the entire `ys` list structure in-place, i.e. it does not need to traverse the second list. This is a form of structural sharing and `List` provides it for free.

#### Inherently persistent objects

If we use plain old Javascript objects not as dictionaries but as trees of nested objects they can exhibit efficient persitent behavior as well, provided we use them accordingly:

```javascript
// Nested objects forming trees

const getTree = (...ks) => o =>
  arrFold(p => k =>
    p[k]) (o) (ks);


const modTree = (...ks) => f => o =>
  arrFold(([p, ref, root]) => (k, i) => {
    if (i === ks.length - 1) {
      p[k] = f(ref[k]);
      return root;
    }
    
    else if (Array.isArray(ref[k]))
      p[k] = ref[k].concat();

    else
      p[k] = Object.assign({}, ref[k]);

    return [p[k], ref[k], root];
  }) (thisify(p => [Object.assign(p, o), o, p])) (ks);

const setTree = (...ks) => v => o =>
  arrFold(([p, ref, root]) => (k, i) => {
    if (i === ks.length - 1) {
      p[k] = v;
      return root;
    }
    
    else if (Array.isArray(ref[k]))
      p[k] = ref[k].concat();

    else
      p[k] = Object.assign({}, ref[k]);

    return [p[k], ref[k], root];
  }) (thisify(p => [Object.assign(p, o), o, p])) (ks);

// auxiliary functions

const thisify = f => f({});

const comp = f => g => x => f(g(x));

const arrFold = f => init => xs => {
  let acc = init;
  
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (xs[i], i);

  return acc;
};

// MAIN

const o = {
  foo: new Map(),
  bar: {bat: {}, baz: ["foo", "bar"]},
  bat: new Set()};

const main = comp(
  modTree("bar", "baz", 0) (s => s.toUpperCase()))
    (setTree("bar", "baz", 1) ("123"));

// compositional non-destructive updates

main(o); // { foo: Map {}, bar: { bat: {}, baz: [ 'FOO', '123' ] }, bat: Set {} }

// structural sharing

main(o).bat === o.bat; // true
getTree("bar", "bat") (main(o)) === getTree("bar", "bat") (o); // true
```
[run code](https://repl.it/@scriptum/WanDependableKernel)

* compositional non-destructive updates
* structural sharing
* inefficient

#### Persistence through functional optics

Plain old Javascript objects are a mutable data type. However, if we use them as nested trees rather than as maps we can regain persistent behavior. The trick is to use them along with functional lenses and other optics, which automatically take care of copying and structural sharing. Lenses are the functional pattern for imperative getters and setters. They are part of a family of optical tools and a rather advanced topic. We will only look more closely into functional optics in subsequent chapters of this course.

#### Persistence through hashed array mapped tries

Persistent data structures maintain persistency by an efficient copy mechanism referred to as structural sharing. If you alter such a data structure only the portion that is affected by the alteration is actually copied, whereas the rest is shared between the current and the previous state. Consequently, all previous states are preserved, because there are no destructive updates anymore. Persistent data types are regularly based on trees. An update of a leave of this tree requires the path to this leave to be copied whereas the rest of the tree can be shared. No matter how ramified the tree is, the efficiency of our copy mechanism is only depends on the depth of the path.

scriptum uses a special variant of a tree to model persistent data structures, namely a trie or more specifically, a hashed array mapped trie (Hamt). `Hamt` exhibits a promising performance, can handle all kinds of types as keys and supplies a pretty straightforward API:

```javascript
Hamt(props)
// takes an object with arbitrary properties
// returns fresh empty Hamt with these extra properties

hamtGet(hamt, k)
// takes a hamt and a key of arbitrary type
// returns the corresponding value

hamtHas(hamt, k)
// takes a hamt and a key
// returns true if the key exists and false otherwise

hamtSet(hamt, props1, props2, k, v)
// takes a hamt, two objects, a key and a value
// returns a new hamt with the value set under the given key

hamtDel(hamt, props, k)
// takes a hamt, an object and a key
// returns a new hamt with the key removed

hamtUpd(hamt, props, k, f)
// takes a hamt, an object, a key and a pure function
// returns a new hamt with the updated value under the given key
```
The principle to modify such a persistent data structure is pretty simple: A function takes at least a `Hamt` instance, a key and an object with some properties and returns a new `Hamt`, where all key/value-pairs are the same except for the selected key with the modified value.

##### An immutable array

We can develop a better feeling for persistent data structures by having a quick glance at a specific implementation. Here is the necessary excerpt from the `Iarray` API to do so:

```javascript
const Iarray = Hamt(
  {length: 0, offset: 0});

const iarrCons = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset - 1},
    xs.offset - 1,
    x);

const iarrSnoc = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset},
    xs.length,
    x);

const iarrFold = f => acc => xs => {
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (hamtGet(xs, i + xs.offset), i);

  return acc;
};

const iarrFromArr = arrFold(
  acc => (x, i) =>
    hamtSet(acc, {}, {length: acc.length + 1, offset: 0}, i, x))
      (Iarray);

const iarrToArr = xs =>
  iarrFold(
    acc => (x, i) => arrSnoc(x) (acc))
      ([])
        (xs);

const xs = iarrFromArr([1, 2, 3, 4, 5]);

iarrToArr(iarrCons(0) (xs)); // [0, 1, 2, 3, 4, 5]
iarrToArr(iarrSnoc(6) (xs)); // [1, 2, 3, 4, 5, 6]
```
[run code](https://repl.it/@scriptum/MessyGlumHexadecimal)

`iarrCons`/`iarrSnoc` are the immutable counterparts of the destructive `unshift`/`push` operations. You have probably seen a crucial downside of `Hamt` already: Since they are not native they require a lot of back and forth transformation. `Hamt` is a trade-off between performance gains through structural sharing on the one hand and performance loss through transformations on the other hand. As a rule of thumb it applies that the benefits outweigh the drawbacks as soon as we deal with either large amounts of data or a lot of modifications or both, of course.

Now we are ready to reimplement the array based and thus inefficient `take` function from the beginning of this chapter. We implement it with the very same algorithm but with `Iarray` as its underlying data structure:

```javascript
const arrTake = n => ([x, ...xs]) =>
  n === 0
    ? []
    : [x].concat(arrTake(n - 1) (xs));

const iarrTake = n => xs => {
  const go = ([y, ys], m) =>
    m === 0
      ? Iarray
      : iarrCons(y) (go(iarrUncons(ys), m - 1));

  return go(iarrUncons(xs), n);
};

const xs = Array(1e5).fill(1).map((x, i) => x + i),
  ys = iarrFromArr(xs);

arrTake(200) (xs);
iarrTake(200) (ys); // way more efficient
```
[run code](https://repl.it/@scriptum/ComplicatedInformalStatistics)

### Editor's note

If you enjoyed this chapter please 🌟 scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-010.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-012.md)
