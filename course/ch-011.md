## Immutability in Languages w/o Purely Functional Data Types

Immutability in a language without purely functional data types entails more tedious and more verbose code. However, the advantages of avoiding this class of side effects outweigh the drawbacks by far. Locating a nasty bug caused by a subtle side effect in a large code base is one of the most frustrating experiences of any programmer.

### Why mutability is harmful

#### Introduction of time

Just like I/O operations mutations are a side effect that introduce time and thus adds complexity to your program. If time matters, it affects the evaluation order:

```javascript
const push = x => xs =>
  (xs.push(x), xs); //  mutation
  
const append = x => xs =>
  xs.concat([x]); // pure

const xs = [1, 2, 3],
  xs_ = [1, 2, 3];
  ys = [1, 2, 3],
  ys_ = [1, 2, 3];

push(4) (xs); // push before
console.log(xs); // logs [1, 2, 3, 4] A

console.log(xs_); // logs [1, 2, 3] A
push(4) (xs_); // push after

append(4) (ys); // append before
console.log(ys); // logs [1, 2, 3] B

console.log(ys_); // logs [1, 2, 3] B
append(4) (ys_); // append after
```
As you can see lines `A` diverge whereas lines `C` converge.

Besides mutations are implicit, that is to say you cannot tell if a function exhibits side effects or not just by looking at its name or the way it is invoked. This makes it more difficult to understand the intention of code without looking into the underlying implementations of the involved functions.

#### Less idempotency

Time has another implication: In the presence of it you need to take into account how often a function is called or if it is called at all:

```javascript
const push = x => xs => (xs.push(x), xs);
const pop = xs => [xs.pop(), xs];
const head = ([x]) => x;

const xs = [],
  ys = [1, 2];

// push(1) (xs); A
console.log(head(xs));

pop(xs); // [1] 
pop(xs); // [] B
pop(xs); // [] C
console.log(head(xs));
```
As you can see you have to be careful if you call the function at all (`A`) or more than once (`B`). Consequently, mutations hamper with idempotency. However, there are also operations with side effects that are idempotent (`C`).

#### Hampering non-strict evaluation

Functional programming embraces lazy evaluation as we have already seen in a previous chapter. Non-strict evaluation is a property of this laziness and renders mutations even more harmful, because it evaluates the arguments only when needed:

```javascript
const nonStrict = thunk => ({valueOf: thunk});
const strict = x => x.valueOf();
const tag = tag => x => (console.log(tag), x);

const safeDiv = x => y =>
  strict(y) === 0
    ? 0 : x / y;

let x = nonStrict(() => tag("x") (1)),
  y = nonStrict(() => tag("y") (2)),
  z = nonStrict(() => tag("z") (0));

// non-strict evaluation

safeDiv(x) (y); // logs "y", "x" and "y"
safeDiv(x) (z); // logs "z"

// strict evaluation

safeDiv(strict(x)) (strict(y)); // logs "x" and "y"
safeDiv(strict(x)) (strict(z)); // logs "x" and "z"
```
[run code](https://repl.it/@scriptum/VerifiableCaringAdware)

With `safeDiv` it is all about the evaluation order, not the result, therefore I use an I/O side effect instead of mutations. Can you see that it is much harder to comprehend the non-strict logging compared to the strict one? Laziness does not play well together with mutations in general, because you often do not know when an argument is actually evaluated.

#### Conclusion

Let us generalize what effect our newly gained insight has on the functional programming experience. Mutations complicates..

* parallelization (through asynchronous computations in Javascript)
* local and equational reasoning

In other words you can rely on side effects, but then it is not functional programming anymore.

### Ignoring mutability

If we should not rely on mutations anymore, how are we supposed to handle Javascript's native data structures which are mutable by design? You may treat them immutable, but it comes at the expense of their efficiency:

```javascript
const take = n => ([x, ...xs]) =>
//                     ^^^^^
  n === 0
    ? []
    : [x].concat(take(n - 1) (xs));
//        ^^^^^^

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // incredible inefficient
```
Both underlined lines of code are responsible for creating brand new copies of the array at each iteration, while previous ones are just garbage collected. This is ridiculously inefficient, especially if you have to deal with larger amounts of data. I would recommend using native types only for small and medium data volumes and resort to more suitable custom types otherwise. The following sections will show the most relevant approaches.

### Confining mutability

#### Keep mutations local
If you insist on relying on mutations in order to use imperative data structures in a natural fashion, you can at least contain the negative implications by keeping side effects local:

```javascript
const push = x => xs =>
  (xs.push(x), xs);

const take = n => xs =>
  n === 0
    ? []
    : push(xs[n - 1]) (take(n - 1) (xs));

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // quite efficient
```
The side effect is only visible in `take`'s scope but not in the global one and is thus better manageable. However, keep in mind that assumed local mutations can still leak into the global scope in unexpected ways, if such functions themselves grow more complex or you partially apply them and reuse intermediate functions within a recursive algorithm. So use them only with great care.

#### Utilize eta abstractions

Another technique to prevent side effects from leaking into the global scope is eta abstraction, that is, adding redundant function layers:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => xs => fold(acc => x =>
//               ^^^^^
  arrCons_(acc) (f(x)))
    ([])
      (xs);
//    ^^^^

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9]
```
[run code](https://repl.it/@scriptum/RaggedAccomplishedQueries)

In the example above the redundant lambda abstraction forces `map` to create a fresh array instance at each iteration.

### Reducing the need of mutability

Related data are often not available in advance at once but gradually as the program progresses. Instead of destructively update an existing data structure with new chunks of data you can only loosely couple it by sharing its structure. Later you are able to recover data relationships by comparing this very structure. Here is a rather contrived example:

```javascript
const foo = {
  keyA: {
    keyB: [1, 2, 3],
    /*...*/
  },
  /*...*/
};

const bar = {
  keyA: {
    keyB: ["a", "b", "c"],
    /*...*/
  },
  /*...*/
};

const baz = {
  keyA: {
    keyB: [true, false, false],
    /*...*/
  },
  /*...*/
};
```
Looking at `foo`, `bar` and `baz` you can easily deduce compound data from its position in the underlying structure: `[1, "a", true]`, `[2, "b", false]` and `[3, "c", false]`. While this form of implicit data association works, it increases the mental load for the programmer the more complex the data structures become.

### Persistent data structures with structural sharing

At a certain point we cannot get around introducing real immutable data types for our compound data. Such types have a persistent structure and a smart copy mechanism that copies only the necessary portion of the structure and shares the rest across instances. Some data structures are inherently persistent, others need specific implementation to exhibit persistent behavior.

#### Inherently persistent lists

The functional single linked `List` type is inherently persistent. We can trivially mimic it in Javascript with a two element array used as a pair tuple:

```javascript
// union constructor

const union = type => (tag, o) =>
  (o[type] = type, o.tag = tag.name || tag, o);
  
const match = (tx, o) =>
  o[tx.tag] (tx);

// LIST

const List = union("List");

const Nil = List("Nil", {});

const Cons = head => tail => List(Cons, {head, tail});

const cons_ = tail => head =>
  List(Cons, {head, tail});

// Monoid

const listAppend = xs => ys =>
  listFoldr(x => acc =>
    Cons(x) (acc)) (ys) (xs);

// Foldable

const listFoldr = f => acc =>
  rec(xs =>
    match(xs, {
      Nil: _ => Base(acc),
      Cons: ({head, tail}) => Call(f(head), Step(tail))
    }));

// trampoline

const rec = f => (...args) => {
  let step = f(...args);
  const stack = [];

  while (step.tag !== "Base") {
    stack.push(step.f);
    step = f(...step.step.args);
  }

  let r = step.x;

  for (let i = stack.length - 1; i >= 0; i--) {
    r = stack[i] (r);
    
    if (r && r.tag === "Base") {
      r = r.x;
      break;
    }
  }

  return r;
};

const Base = x =>
  ({tag: "Base", x});

const Call = (f, step) =>
  ({tag: "Call", f, step});

const Step = (...args) =>
  ({tag: "Step", args});

// MAIN

const xs = Cons(1) (Cons(2) (Cons(3) (Nil))),
  ys = Cons(4) (Cons(5) (Cons(6) (Nil)));

listAppend(xs) (ys); // Cons(1) (Cons(2) (Cons(3) (Cons(4) (Cons(5) (Cons(6) (Nil))))))
```
[run code](https://repl.it/@scriptum/PeriodicMoccasinUpgrade)

The algorithm above right associatively folds `xs` and as soon as it reaches `Nil` it appends the entire `ys` list structure in-place, i.e. it does not need to traverse the second list. This is a form of structural sharing and `List` provides it for free.

#### Inherently persistent trees

What makes singled linked lists inherently persistent is the tree structure they shape, even if it is a special one. Given an arbitrarily tree we can easily just copy the path to the node to be changed, whereas all the other branches can be shared. Consequently, we can utilize persistence and sharing with plain old Javascript objects as long as we encode trees:

```javascript
// Nested objects forming trees

const getTree = (...ks) => o =>
  arrFold(p => k =>
    p[k]) (o) (ks);


const modTree = (...ks) => f => o =>
  arrFold(([p, ref, root]) => (k, i) => {
    if (i === ks.length - 1) {
      p[k] = f(ref[k]);
      return root;
    }
    
    else if (Array.isArray(ref[k]))
      p[k] = ref[k].concat();

    else
      p[k] = Object.assign({}, ref[k]);

    return [p[k], ref[k], root];
  }) (thisify(p => [Object.assign(p, o), o, p])) (ks);

const setTree = (...ks) => v => o =>
  arrFold(([p, ref, root]) => (k, i) => {
    if (i === ks.length - 1) {
      p[k] = v;
      return root;
    }
    
    else if (Array.isArray(ref[k]))
      p[k] = ref[k].concat();

    else
      p[k] = Object.assign({}, ref[k]);

    return [p[k], ref[k], root];
  }) (thisify(p => [Object.assign(p, o), o, p])) (ks);

// auxiliary functions

const thisify = f => f({});

const comp = f => g => x => f(g(x));

const arrFold = f => init => xs => {
  let acc = init;
  
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (xs[i], i);

  return acc;
};

// MAIN

const o = {
  foo: new Map(),
  bar: {bat: {}, baz: ["foo", "bar"]},
  bat: new Set()};

const main = comp(
  modTree("bar", "baz", 0) (s => s.toUpperCase()))
    (setTree("bar", "baz", 1) ("123"));

// compositional non-destructive updates

main(o); // { foo: Map {}, bar: { bat: {}, baz: [ 'FOO', '123' ] }, bat: Set {} }

// structural sharing

main(o).bat === o.bat; // true
getTree("bar", "bat") (main(o)) === getTree("bar", "bat") (o); // true
```
[run code](https://repl.it/@scriptum/WanDependableKernel)

With this small set of functions we can perform basic, composable, non-destructive updates. Now you may object that one of the main use cases of Javascript objects are dictionaries and our approach does not get us anything in this respect. And you would be right.

Please note that there is a more advanced technique that enables us to perform far more complex, composable, non-destructive updates on tree data structures: functional optics. We will learn about this technique in a subsequent chapter of this course.

#### Hashed array mapped tries

Persistent data structures maintain persistency by an efficient copy mechanism referred to as structural sharing. If you alter such a data structure only the portion that is affected by the alteration is actually copied, whereas the rest is shared between the current and the previous state. Consequently, all previous states are preserved, because there are no destructive updates anymore. Persistent data types are regularly based on trees. An update of a leave of this tree requires the path to this leave to be copied whereas the rest of the tree can be shared. No matter how ramified the tree is, the efficiency of our copy mechanism is only depends on the depth of the path.

scriptum uses a special variant of a tree to model persistent data structures, namely a trie or more specifically, a hashed array mapped trie (Hamt). `Hamt` exhibits a promising performance, can handle all kinds of types as keys and supplies a pretty straightforward API:

```javascript
Hamt(props)
// takes an object with arbitrary properties
// returns fresh empty Hamt with these extra properties

hamtGet(hamt, k)
// takes a hamt and a key of arbitrary type
// returns the corresponding value

hamtHas(hamt, k)
// takes a hamt and a key
// returns true if the key exists and false otherwise

hamtSet(hamt, props1, props2, k, v)
// takes a hamt, two objects, a key and a value
// returns a new hamt with the value set under the given key

hamtDel(hamt, props, k)
// takes a hamt, an object and a key
// returns a new hamt with the key removed

hamtUpd(hamt, props, k, f)
// takes a hamt, an object, a key and a pure function
// returns a new hamt with the updated value under the given key
```
The principle to modify such a persistent data structure is pretty simple: A function takes at least a `Hamt` instance, a key and an object with some properties and returns a new `Hamt`, where all key/value-pairs are the same except for the selected key with the modified value.

In order to gain a better understanding of hashed array mapped tries we need to implement a specific immutable data structure. Since the implementation of an immutable map or dictionary is quite elaborate, we will demonstrate the approach using an immutable array:

```javascript
const Iarray = Hamt(
  {length: 0, offset: 0});

const iarrCons = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset - 1},
    xs.offset - 1,
    x);

const iarrSnoc = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset},
    xs.length,
    x);

const iarrFold = f => acc => xs => {
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (hamtGet(xs, i + xs.offset), i);

  return acc;
};

const iarrFromArr = arrFold(
  acc => (x, i) =>
    hamtSet(acc, {}, {length: acc.length + 1, offset: 0}, i, x))
      (Iarray);

const iarrToArr = xs =>
  iarrFold(
    acc => (x, i) => arrSnoc(x) (acc))
      ([])
        (xs);

const xs = iarrFromArr([1, 2, 3, 4, 5]);

iarrToArr(iarrCons(0) (xs)); // [0, 1, 2, 3, 4, 5]
iarrToArr(iarrSnoc(6) (xs)); // [1, 2, 3, 4, 5, 6]
```
[run code](https://repl.it/@scriptum/MessyGlumHexadecimal)

`iarrCons`/`iarrSnoc` are the immutable counterparts of the destructive `unshift`/`push` operations. You have probably seen a crucial downside of `Hamt` already: Since they are not native they require a lot of back and forth transformation. `Hamt` is a trade-off between performance gains through structural sharing on the one hand and performance loss through transformations on the other hand. As a rule of thumb it applies that the benefits outweigh the drawbacks as soon as we deal with either large amounts of data or a lot of modifications or both, of course.

Now we are ready to reimplement the array based and thus inefficient `take` function from the beginning of this chapter. We implement it with the very same algorithm but with `Iarray` as its underlying data structure:

```javascript
const arrTake = n => ([x, ...xs]) =>
  n === 0
    ? []
    : [x].concat(arrTake(n - 1) (xs));

const iarrTake = n => xs => {
  const go = ([y, ys], m) =>
    m === 0
      ? Iarray
      : iarrCons(y) (go(iarrUncons(ys), m - 1));

  return go(iarrUncons(xs), n);
};

const xs = Array(1e5).fill(1).map((x, i) => x + i),
  ys = iarrFromArr(xs);

arrTake(200) (xs);
iarrTake(200) (ys); // way more efficient
```
[run code](https://repl.it/@scriptum/ComplicatedInformalStatistics)

In Javascript such persistent data types are not as seamlessly incorporated as in languages with native support, of course. However, the somewhat cumbersome handling is justified by being able to program against a reliable and predictable APIs instead of relying on subtle and counterintuitive side effects.

### Editor's note

If you enjoyed this chapter please 🌟 scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-010.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-012.md)
